{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHhNmRx33lgs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display\n",
    "from sklearn.compose import make_column_selector as selector, ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BIC, K2, MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from imblearn.over_sampling import RandomOverSampler, BorderlineSMOTE, SMOTE, ADASYN\n",
    "\n",
    "# import auxiliary functions:\n",
    "from utils.helpers import plot_label_dist, plot_bn_graph, drop_col, drop_dups, set_coltypes, merge_bins, bin_features_mdl, select_edges\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "colormap = ['#d73027', '#fc8d59', '#fee090', '#ffffbf', '#e0f3f8', '#91bfdb', '#4575b4']\n",
    "\n",
    "dir = '/home/user/Documents' # specify path where the data live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOX7HBEF55EA"
   },
   "source": [
    "## 1. Inspect the data\n",
    "* load the data,\n",
    "* display the structure,\n",
    "* display the statistics for each of the descriptors,\n",
    "* drop descriptors with low variability (one value has occurence of 95% or more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "fFaSDOos301t",
    "outputId": "ad2e2e86-0b39-471a-b504-73c0ea9d3332"
   },
   "outputs": [],
   "source": [
    "# set options to display all columns in df and for sns style:\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "# verify CUDA and PyTorch compatibility\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "  \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # set to the GPU ID you want to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# load the data:\n",
    "data_tve = pd.read_csv(os.path.join(dir, 'laccase-f-tve.csv'), sep=',')\n",
    "data_mth = pd.read_csv(os.path.join(dir, 'laccase-f-mth.csv'), sep=',')\n",
    "data_bpu = pd.read_csv(os.path.join(dir, 'laccase-bpu-lac.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define preprocessing rules for the ordinal and continuous descriptors\n",
    "\n",
    "For the ordinals, we are essentially choosing between 2 strategies:\n",
    "\n",
    "* using corser binning \n",
    "* using one-hot-encoding.\n",
    "\n",
    "For the continuous, we are choosing between \n",
    "\n",
    "* min-max scaling (with the additional option to log-transform)\n",
    "* standard scaling (with the additional option to log-transform).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ordinals(ord_cols_train, ord_cols_test, ohe=False):\n",
    "    '''\n",
    "    function that label-encodes the binned ordinal columns\n",
    "    returns labels corresponding to bins for the training data and maps them to the test data\n",
    "    \n",
    "    args:\n",
    "    * ord_cols_train: pd.DataFrame of ordinal descriptors containing training examples \n",
    "    * ord_cols_test: pd.DataFrame of ordinal descriptors containing test examples \n",
    "    * ohe: if True, uses one-hot-encoding is used, otherwise - coarser binning with subsequent label-encoding; defaults to False\n",
    "    '''\n",
    "             \n",
    "    ord_cols_train_cp = ord_cols_train.copy()\n",
    "    ord_cols_test_cp = ord_cols_test.copy()\n",
    "    \n",
    "    if ohe==True:\n",
    "        # one-hot encode ordinals:\n",
    "        print('Applying one-hot encoding to ordinal features...')\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #OneHotEncoder(handle_unknown='ignore', categories='auto')\n",
    "        ord_cols_train_cp = encoder.fit_transform(ord_cols_train_cp)\n",
    "        ohe_labels = encoder.get_feature_names_out(ord_cols_train.columns.to_list())\n",
    "        ord_cols_train = pd.DataFrame(ord_cols_train_cp, index=ord_cols_train.index, columns=ohe_labels)             \n",
    "        ord_cols_test = pd.DataFrame(encoder.transform(ord_cols_test_cp), index=ord_cols_test.index, columns=ohe_labels)\n",
    "            \n",
    "    elif ohe==False:   \n",
    "        print('Applying binning with label-encoding to ordinal features...')\n",
    "        # bin ordinals from the training set and label-encode:\n",
    "        ord_cols_train_cp = ord_cols_train_cp.apply(merge_bins)\n",
    "        ord_cols_train = ord_cols_train_cp\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        invdict = {'var':[], 'bin':[], 'label':[]}\n",
    "        for i, col in enumerate(list(ord_cols_train.columns)):\n",
    "            le.fit(ord_cols_train.iloc[:, i])\n",
    "            ord_cols_train.iloc[:, i] = le.transform(ord_cols_train.iloc[:, i])\n",
    "            inv = le.inverse_transform(ord_cols_train.iloc[:, i].unique())\n",
    "            invdict['var'].append([col]*len(inv))\n",
    "            invdict['label'].append(ord_cols_train.iloc[:, i].unique())\n",
    "            invdict['bin'].append(inv)\n",
    "            \n",
    "        # save the bins and the encodings to use for the test data and decoding:\n",
    "        le_inv = pd.DataFrame(invdict)\n",
    "        le_inv_exp = le_inv.explode(['var', 'bin', 'label']).reset_index(drop=True)        \n",
    "        \n",
    "        for col in list(ord_cols_test.columns):\n",
    "            lookup_table = le_inv_exp[le_inv_exp['var']==col]\n",
    "            \n",
    "            interval_index = pd.Index(lookup_table['bin']) # create IntervalIndex:\n",
    "            mapped_bins = interval_index.get_indexer(ord_cols_test[col]) # map values to bins:\n",
    "            labs = lookup_table['label'].iloc[mapped_bins].reset_index(drop=True) \n",
    "            ord_cols_test[col] = labs.to_numpy()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid preprocessing method')\n",
    "    \n",
    "    return  ord_cols_train, ord_cols_test\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def process_continuous (cont_cols_train, cont_cols_test, log=False, scaling=None):\n",
    "    '''\n",
    "    function that preprocesses continuous columns:\n",
    "    * log-transforms if all values in the column (based on the training data) that are positive \n",
    "    * scales all columns (either min-max or standardization - based on the option chosen)\n",
    "    returns log-transformed and scaled values\n",
    "    '''\n",
    "    \n",
    "    # find columns where all values are strictly positive and log-transform only these:\n",
    "    positive_columns = [col for col in cont_cols_train.columns if (cont_cols_train[col] > 0).all()]\n",
    "    \n",
    "    if log==True:\n",
    "        # transform only columns where all values are positive:\n",
    "        print('Log-transforming descriptors with non-negative values.\\n')\n",
    "        cont_cols_train[positive_columns] = cont_cols_train[positive_columns].applymap(lambda x: np.log(x))\n",
    "        \n",
    "        test_positive = [col for col in cont_cols_test.columns if (cont_cols_test[col] > 0).all()]\n",
    "          \n",
    "        s = len(set(test_positive).symmetric_difference(set(positive_columns)))\n",
    "    \n",
    "        cont_cols_test[positive_columns] = cont_cols_test[positive_columns].applymap(lambda x: np.log(x) if x>0 else 0.0)\n",
    "        \n",
    "        if s > 0:\n",
    "            print(f'{s} columns in the test data contain non-positive values. The logs for non-positive values will be set to 0.\\nTry turning off the log-option.\\n')\n",
    "        \n",
    "      \n",
    "    if scaling=='min-max':\n",
    "        \n",
    "        # scale columns if no division by 0 occurs:\n",
    "        sc_columns = (cont_cols_train.max()-cont_cols_train.min()!=0)\n",
    "        sc_cols = sc_columns.index[sc_columns == True].tolist()\n",
    "        print('Applying min-max scaling to continuous features...')\n",
    "        train_min, train_max_min = cont_cols_train[sc_cols].min(), cont_cols_train[sc_cols].max()-cont_cols_train[sc_cols].min()\n",
    "        cont_cols_train[sc_cols] = cont_cols_train[sc_cols].subtract(train_min).div(train_max_min) \n",
    "        cont_cols_test[sc_cols] = cont_cols_test[sc_cols].subtract(train_min).div(train_max_min)\n",
    "    \n",
    "    if scaling=='standard':\n",
    "        \n",
    "        # scale columns if no division by 0 occurs:\n",
    "        sc_columns = (cont_cols_train.std()!=0)\n",
    "        sc_cols = sc_columns.index[sc_columns == True].tolist()\n",
    "        print('Applying standard scaling to continuous features...')\n",
    "        train_mean = cont_cols_train[sc_cols].mean()\n",
    "        train_sd = cont_cols_train[sc_cols].std()\n",
    "        cont_cols_train[sc_cols] = cont_cols_train[sc_cols].subtract(train_mean).div(train_sd) \n",
    "        cont_cols_test[sc_cols] = cont_cols_test[sc_cols].subtract(train_mean).div(train_sd) \n",
    "                \n",
    "    return cont_cols_train, cont_cols_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, seed, preprocessing=None, log=False, ohe=False):\n",
    "    \n",
    "    '''\n",
    "    function that preprocesses the input as follows:\n",
    "    * drops low-variance features\n",
    "    * splits the input set into training and test sets\n",
    "    * performs variable selection by building a Bayesian Network on the training set and identifying relevant edges (w.r.t to the target)\n",
    "    * bins the ordinal features for more stability and encodes them \n",
    "    * log-transforms and/ or min-max scales the continuous features\n",
    "    \n",
    "    preprocessing options:\n",
    "    None: only removes duplicates and MVs and performs the data split\n",
    "    'scaling': treats all features as continuous and standardizes all features\n",
    "    'mixed': applies binning to the ordinals and log-transform and/or min-max scaling to the continuous predictors\n",
    "    returns preprocessed training data, preprocessed test data, training labels and test labels\n",
    "    '''\n",
    "   \n",
    "    # STEP 1. Define dtypes, replace the only MV (in mth) with 0:\n",
    "    data = drop_dups(data)\n",
    "    data = set_coltypes(data)\n",
    "    \n",
    "    # STEP 2. Split the data into train and test, separate the target and the descriptors:\n",
    "  \n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data.drop('Oxd', axis=1), data['Oxd'], test_size=0.2, random_state=seed)   \n",
    "    plot_label_dist(train_labels, seed, colormap=colormap)\n",
    "    \n",
    "    \n",
    "    # STEP 3. Drop cols with low variability in train, discretize the rest of the columns:\n",
    "    train_data = drop_col(train_data)\n",
    "    test_data = test_data[train_data.columns]   \n",
    "        \n",
    "    # STEP 4. Preprocess the variables depending on the preprocessing method:    \n",
    "    if preprocessing == 'scaling': \n",
    "        processed_train, processed_test = process_continuous(train_data, test_data, log=log, scaling='standard')\n",
    "        \n",
    "   \n",
    "    elif preprocessing == 'mixed': \n",
    "        # separate features into different datatypes\n",
    "        ord_feat_train = train_data.select_dtypes(include=['int64', 'float64'])\n",
    "        ord_feat_test = test_data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "        # process ordinals\n",
    "        ord_feat_train_cp, ord_feat_test_cp = process_ordinals(ord_feat_train, ord_feat_test, ohe=ohe)\n",
    "        \n",
    "        cont_feat_train = train_data.select_dtypes(exclude=['int64', 'float64'])\n",
    "        cont_feat_test = test_data.select_dtypes(exclude=['int64', 'float64'])    \n",
    "        \n",
    "        # process continuous\n",
    "        cont_feat_train_cp, cont_feat_test_cp = process_continuous(cont_feat_train, cont_feat_test, log=log, scaling='standard') # 'min-max'\n",
    "        \n",
    "        processed_train, processed_test =  pd.concat([ord_feat_train_cp, cont_feat_train_cp], axis = 1), pd.concat([ord_feat_test_cp, cont_feat_test_cp], axis = 1)\n",
    "    elif preprocessing == None:\n",
    "        print('Variables will not be transformed...')\n",
    "        processed_train, processed_test = train_data, test_data\n",
    "    else:\n",
    "        raise ValueError('Invalid preprocessing method')\n",
    "    # check if the train data contain MV's\n",
    "    if (processed_train.isnull().values.any() or processed_test.isnull().values.any()):\n",
    "        \n",
    "        print('Either the training or test data contain missing values! Dropping obs with NaNs...\\n')\n",
    "        if processed_train.isnull().values.any():\n",
    "            processed_train = processed_train.dropna()\n",
    "        else:\n",
    "            processed_test = processed_test.dropna()\n",
    "\n",
    "    \n",
    "    return processed_train, processed_test, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GN data augmentation\n",
    "\n",
    "This section contains code modifications for augmenting the data with GN-contaminated samples.\n",
    "\n",
    "*NOTE:* \n",
    "The noise is injected into the training data prior to preprocessing. Formally, for each descriptor $j = 1, \\dots, p$ the perturbed feature is defined as $x_{\\cdot j} + \\xi_j$, where  $\\xi_j \\sim \\mathcal{N}(0, \\eta \\sigma_j)$ and $\\eta$ represents the noise intensity. To accommodate ordinal descriptors, noise is added and then rounded to the nearest integer, with values clipped to remain within observed bounds. The target labels remain unchanged.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "def process_continuous (cont_cols_train, cont_cols_test, log=False, scaling=None):\n",
    "    '''\n",
    "    function that preprocesses continuous columns:\n",
    "    * log-transforms if all values in the column (based on the training data) are positive \n",
    "    * min-max scales all columns\n",
    "    returns log-transformed and scaled values\n",
    "    '''\n",
    "    \n",
    "    # find columns where all values are strictly positive and log-transform only these:\n",
    "    positive_columns = [col for col in cont_cols_train.columns if (cont_cols_train[col] > 0).all()]\n",
    "    \n",
    "    \n",
    "    # add GN to the training data:  \n",
    "    noise_std = 0.2  # define noise intensity: set to 0.20*standard deviation\n",
    "\n",
    "    cont_cols_train_gn =  cont_cols_train.copy()\n",
    "    # add noise to original (unstandardized) features:\n",
    "    for col in list(cont_cols_train.columns):\n",
    "        std_dev = cont_cols_train[col].std()\n",
    "        np.random.seed(0) \n",
    "        noise = np.random.normal(0, noise_std * std_dev, size=cont_cols_train.shape[0])\n",
    "        cont_cols_train_gn[col] += noise  # Add noise\n",
    "      \n",
    "    # augment the original data with the noised data:  \n",
    "    print('Non-contaminated data: ', cont_cols_train.shape)\n",
    "    print('Contaminated data: ', cont_cols_train_gn.shape)\n",
    "    \n",
    "    cont_cols_train_aug = pd.concat([ cont_cols_train,  cont_cols_train_gn])\n",
    "    print('Augmented data: ', cont_cols_train_aug.shape)\n",
    "    print('')\n",
    "    \n",
    "    # reassign: \n",
    "    cont_cols_train = cont_cols_train_aug\n",
    "    \n",
    "    if log==True:\n",
    "        # transform only columns where all values are positive:\n",
    "        print('Log-transforming descriptors with non-negative values.\\n')\n",
    "        cont_cols_train[positive_columns] = cont_cols_train[positive_columns].applymap(lambda x: np.log(x))\n",
    "        \n",
    "        test_positive = [col for col in cont_cols_test.columns if (cont_cols_test[col] > 0).all()]\n",
    "          \n",
    "        s = len(set(test_positive).symmetric_difference(set(positive_columns)))\n",
    "    \n",
    "        cont_cols_test[positive_columns] = cont_cols_test[positive_columns].applymap(lambda x: np.log(x) if x>0 else 0.0)\n",
    "        \n",
    "        if s > 0:\n",
    "            print(f'{s} columns in the test data contain non-positive values. The logs for non-positive values will be set to 0.\\nTry turning off the log-option.\\n')\n",
    "        \n",
    "      \n",
    "    if scaling=='min-max':\n",
    "        \n",
    "        # scale columns if no division by 0 occurs:\n",
    "        sc_columns = (cont_cols_train.max()-cont_cols_train.min()!=0)\n",
    "        sc_cols = sc_columns.index[sc_columns == True].tolist()\n",
    "        print('Applying min-max scaling to continuous features...')\n",
    "        train_min, train_max_min = cont_cols_train[sc_cols].min(), cont_cols_train[sc_cols].max()-cont_cols_train[sc_cols].min()\n",
    "        cont_cols_train[sc_cols] = cont_cols_train[sc_cols].subtract(train_min).div(train_max_min) \n",
    "        cont_cols_test[sc_cols] = cont_cols_test[sc_cols].subtract(train_min).div(train_max_min)\n",
    "    \n",
    "    if scaling=='standard':\n",
    "        \n",
    "        # scale columns if no division by 0 occurs:\n",
    "        sc_columns = (cont_cols_train.std()!=0)\n",
    "        sc_cols = sc_columns.index[sc_columns == True].tolist()\n",
    "        print('Applying standard scaling to continuous features...')\n",
    "        train_mean = cont_cols_train[sc_cols].mean()\n",
    "        train_sd = cont_cols_train[sc_cols].std()\n",
    "        cont_cols_train[sc_cols] = cont_cols_train[sc_cols].subtract(train_mean).div(train_sd) \n",
    "        cont_cols_test[sc_cols] = cont_cols_test[sc_cols].subtract(train_mean).div(train_sd) \n",
    "                \n",
    "    return cont_cols_train, cont_cols_test\n",
    "\n",
    "\n",
    "def process_ordinals(ord_cols_train, ord_cols_test, ohe=False):\n",
    "    '''\n",
    "    function that label-encodes the binned ordinal columns\n",
    "    returns labels corresponding to bins for the training data and maps them to the test data\n",
    "    '''\n",
    "        # add GN to the training data:  \n",
    "    noise_std = 0.2  # define noise intensity: set to 10% of standard deviation\n",
    "\n",
    "    ord_cols_train_gn =  ord_cols_train.copy()\n",
    "    # augment ordinal features carefully (rounding to nearest category):\n",
    "    for col in list(ord_cols_train.columns):\n",
    "        std_dev = ord_cols_train[col].std()\n",
    "        np.random.seed(0) \n",
    "        noise = np.random.normal(0, noise_std * std_dev, size=ord_cols_train.shape[0])\n",
    "        ord_cols_train_gn[col] = np.round(ord_cols_train_gn[col] + noise).clip(ord_cols_train[col].min(), ord_cols_train[col].max())\n",
    "        # ensure ordinal values remain integers\n",
    "        ord_cols_train_gn[col] = ord_cols_train_gn[col].astype(int)  \n",
    "        \n",
    "        \n",
    "    # augment the original data with the noised data:  \n",
    "    print('Non-contaminated data: ', ord_cols_train.shape)\n",
    "    print('Contaminated data: ', ord_cols_train_gn.shape)\n",
    "    \n",
    "    ord_cols_train_aug = pd.concat([ord_cols_train, ord_cols_train_gn])\n",
    "    print('Augmented data: ', ord_cols_train_aug.shape)\n",
    "    print('')\n",
    "    \n",
    "    # reassign: \n",
    "    ord_cols_train = ord_cols_train_aug\n",
    "\n",
    "    \n",
    "             \n",
    "    ord_cols_train_cp = ord_cols_train.copy()\n",
    "    ord_cols_test_cp = ord_cols_test.copy()\n",
    "    \n",
    "    if ohe==True:\n",
    "        # one-hot encode ordinals:\n",
    "        print('Applying one-hot encoding to ordinal features...')\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #OneHotEncoder(handle_unknown='ignore', categories='auto')\n",
    "        ord_cols_train_cp = encoder.fit_transform(ord_cols_train_cp)\n",
    "        ohe_labels = encoder.get_feature_names_out(ord_cols_train.columns.to_list())\n",
    "        ord_cols_train = pd.DataFrame(ord_cols_train_cp, index=ord_cols_train.index, columns=ohe_labels)             \n",
    "        ord_cols_test = pd.DataFrame(encoder.transform(ord_cols_test_cp), index=ord_cols_test.index, columns=ohe_labels)\n",
    "            \n",
    "    elif ohe==False:   \n",
    "        print('Applying binning with label-encoding to ordinal features...')\n",
    "        # bin ordinals from the training set and label-encode:\n",
    "        ord_cols_train_cp = ord_cols_train_cp.apply(merge_bins)\n",
    "        ord_cols_train = ord_cols_train_cp\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        invdict = {'var':[], 'bin':[], 'label':[]}\n",
    "        for i, col in enumerate(list(ord_cols_train.columns)):\n",
    "            le.fit(ord_cols_train.iloc[:, i])\n",
    "            ord_cols_train.iloc[:, i] = le.transform(ord_cols_train.iloc[:, i])\n",
    "            inv = le.inverse_transform(ord_cols_train.iloc[:, i].unique())\n",
    "            invdict['var'].append([col]*len(inv))\n",
    "            invdict['label'].append(ord_cols_train.iloc[:, i].unique())\n",
    "            invdict['bin'].append(inv)\n",
    "        # save the bins and the encodings to use for the test data and decoding:\n",
    "        le_inv = pd.DataFrame(invdict)\n",
    "        le_inv_exp = le_inv.explode(['var', 'bin', 'label']).reset_index(drop=True)        \n",
    "        \n",
    "        for col in list(ord_cols_test.columns):\n",
    "            lookup_table = le_inv_exp[le_inv_exp['var']==col]\n",
    "            \n",
    "            interval_index = pd.Index(lookup_table['bin']) # create IntervalIndex:\n",
    "            mapped_bins = interval_index.get_indexer(ord_cols_test[col]) # map values to bins:\n",
    "            labs = lookup_table['label'].iloc[mapped_bins].reset_index(drop=True) \n",
    "            ord_cols_test[col] = labs.to_numpy()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid preprocessing method')\n",
    "    \n",
    "    return  ord_cols_train, ord_cols_test\n",
    "    \n",
    "\n",
    "\n",
    "def preprocess(data, seed, preprocessing='mixed', log=False, ohe=True):\n",
    "    \n",
    "    '''\n",
    "    function that preprocesses the input as follows:\n",
    "    * drops low-variance features\n",
    "    * splits the input set into training and test sets\n",
    "    * performs variable selection by building a Bayesian Network on the training set and identifying relevant edges (w.r.t to the target)\n",
    "    * bins the ordinal features for more stability and encodes them \n",
    "    * log-transforms and/ or min-max scales the continuous features\n",
    "    \n",
    "    preprocessing options:\n",
    "    None: only removes duplicates and MVs and performs the data split\n",
    "    'scaling': treats all features as continuous and standardizes all features\n",
    "    'mixed': applies binning to the ordinals and log-transform and/or min-max scaling to the continuous predictors\n",
    "    returns preprocessed training data, preprocessed test data, training labels and test labels\n",
    "    '''\n",
    "   \n",
    "\n",
    "    # STEP 1. Define dtypes, replace the only MV (in mth) with 0:\n",
    "    data = drop_dups(data)\n",
    "    data = set_coltypes(data)\n",
    "    \n",
    "    # STEP 2. Split the data into train and test, separate the target and the descriptors:\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data.drop('Oxd', axis=1), data['Oxd'], test_size=0.20, random_state=seed)\n",
    "        \n",
    "    plot_label_dist(train_labels, seed)\n",
    "    \n",
    "    \n",
    "    # STEP 3. Drop cols with low variability in train, discretize the rest of the columns:\n",
    "    train_data = drop_col(train_data)\n",
    "    test_data = test_data[train_data.columns]   \n",
    "        \n",
    "    # STEP 4. Preprocess the variables depending on the preprocessing method:    \n",
    "    if preprocessing == 'scaling': \n",
    "        processed_train, processed_test = process_continuous(train_data, test_data, log=log, scaling='standard')\n",
    "        \n",
    "   \n",
    "    elif preprocessing == 'mixed': \n",
    "        # separate features into different datatypes\n",
    "        ord_feat_train = train_data.select_dtypes(include='int64')\n",
    "        ord_feat_test = test_data.select_dtypes(include='int64')\n",
    "\n",
    "   \n",
    "    \n",
    "        # process ordinals\n",
    "        ord_feat_train_cp, ord_feat_test_cp = process_ordinals(ord_feat_train, ord_feat_test, ohe=ohe)\n",
    "        \n",
    "        cont_feat_train = train_data.select_dtypes(exclude='int64')\n",
    "        cont_feat_test = test_data.select_dtypes(exclude='int64')    \n",
    "        \n",
    "        # process continuous\n",
    "        cont_feat_train_cp, cont_feat_test_cp = process_continuous(cont_feat_train, cont_feat_test, log=log, scaling='standard') # 'min-max'\n",
    "        \n",
    "        \n",
    "        \n",
    "        processed_train, processed_test =  pd.concat([ord_feat_train_cp, cont_feat_train_cp], axis = 1), pd.concat([ord_feat_test_cp, cont_feat_test_cp], axis = 1)\n",
    "\n",
    "    elif preprocessing == None:\n",
    "        print('Variables will not be transformed...')\n",
    "        processed_train, processed_test = train_data, test_data\n",
    "    else:\n",
    "        raise ValueError('Invalid preprocessing method')\n",
    "    # check if the train data contain MV's\n",
    "    if (processed_train.isnull().values.any() or processed_test.isnull().values.any()):\n",
    "        \n",
    "        print('Either the training or test data contain missing values! Dropping obs with NaNs...\\n')\n",
    "        if processed_train.isnull().values.any():\n",
    "            processed_train = processed_train.dropna()\n",
    "        else:\n",
    "            processed_test = processed_test.dropna()\n",
    "    \n",
    "\n",
    "        # augment labels (as they are):\n",
    "    train_labels = pd.concat([train_labels, train_labels])           \n",
    "        \n",
    "    return processed_train, processed_test, train_labels, test_labels\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the class for training the classical classifiers\n",
    "\n",
    "The class defines hyperparameter tuning procedure for each of the classifiers: LogReg, SVC, RFC and GradBoostC by selecting the best hyperparams over the predefined grids using 5-fold CV for a specific seed (data split). Contains the possibility to balance the data using several upsampling methods from the `imblearn` library - such as RandomOverSampler, BorderlineSMOTE, SMOTE, ADASYN, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunClf:\n",
    "    '''\n",
    "    defines the inner loop of the classifier's hyperparameter tunung by\n",
    "    selecting the best hyperparams using 5-fold CV for a certain seed\n",
    "    * * * * * * * * * * * * *\n",
    "    inputs: features,\n",
    "            labels,\n",
    "            method ('LogReg', 'SVM', 'RF' or 'GBoost'),\n",
    "            balanced ('UndersamplingSMOTE', 'SMOTE', 'BorderlineSMOTE', None)\n",
    "    outputs: best_pars (object (list) storing the params of the best model) for a data split defined by a single seed\n",
    "    this class is deterministic in the sense that the only randomness is defined by the data split (defined \"outside\"),\n",
    "    for all models and the CV strategy the random_state is set to 0 to control for the random initializations\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, features, labels, method, balanced=None, scoring='f1'):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.method = method\n",
    "        self.balanced = balanced\n",
    "        self.scoring = scoring\n",
    "        self.fitted = None  \n",
    "        self.model_configs = {\n",
    "                    'LogReg': {\n",
    "                        'params': {\n",
    "                            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                            'l1_ratio': [0.05, 0.1, 0.25, 0.5, 0.75, 0.95, 1],\n",
    "                            'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 2, 5, 10, 15]\n",
    "                                },\n",
    "                        'model': LogisticRegression(max_iter=1000, random_state=0, solver='saga'),\n",
    "                                },\n",
    "\n",
    "                    'SVC':{\n",
    "                        'params': {\n",
    "                            'C': [0.01, 0.05, 0.1, 0.25, 0.5, 1, 2, 5, 10, 20],\n",
    "                            'kernel': ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "                            },\n",
    "                        'model': SVC(probability=True), \n",
    "                        },\n",
    "                    \n",
    "                    'RFC':{\n",
    "                        'params': {\n",
    "                          'n_estimators': [25, 50, 75, 100, 200, 300, 500, 1000],\n",
    "                          'max_depth': [None, 5, 7, 10, 20],\n",
    "                          'min_samples_split': [5, 10, 15, 25],\n",
    "                          'min_samples_leaf': [5, 10, 20]\n",
    "                          },\n",
    "                        'model': RandomForestClassifier(random_state=0),\n",
    "                    },\n",
    "\n",
    "                    'GradBoostC':{\n",
    "                        'params': {\n",
    "                          'n_estimators': [25, 50, 75, 100, 200, 300, 500, 1000],\n",
    "                          'min_samples_split': [5, 10, 15, 25],\n",
    "                          'min_samples_leaf': [5, 10, 20]\n",
    "                          },\n",
    "                        'model': GradientBoostingClassifier(random_state=0, criterion='friedman_mse'),\n",
    "                    },        \n",
    "            }\n",
    "\n",
    "\n",
    "        self.params = self.model_configs[method]['params']\n",
    "        self.model = self.model_configs[method]['model']\n",
    "    \n",
    "        if self.method=='SVC':\n",
    "            self.model.random_state = 0\n",
    "\n",
    "    def resample_data(self):\n",
    "        resampled_features, resampled_labels = self.balanced.fit_resample(self.features, self.labels)\n",
    "        return resampled_features, resampled_labels\n",
    "\n",
    "\n",
    "    def fit_tuned(self, cvseed=42):  \n",
    "        if self.balanced:\n",
    "            resampled_features, resampled_labels = self.resample_data()\n",
    "        else:\n",
    "            resampled_features, resampled_labels = self.features, self.labels\n",
    "            \n",
    "        search = GridSearchCV(self.model, self.params, scoring=self.scoring,\n",
    "                                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=cvseed),\n",
    "                                error_score=np.nan)\n",
    "        search.fit(resampled_features, resampled_labels)\n",
    "        fitted = search.best_estimator_\n",
    "        \n",
    "        return fitted, resampled_features, resampled_labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the model evaluation function\n",
    "\n",
    "\n",
    "Create classification report (computes classification Accuracy, Precision, Recall, F1, and AUROC).\n",
    "Plots AUROC and the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blsmote = BorderlineSMOTE(sampling_strategy='minority',\n",
    "                          kind='borderline-1',\n",
    "                          m_neighbors=10,\n",
    "                          random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "def plot_roc(fpr, tpr, cm, method, seed):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    \n",
    "    # calculate ROC AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve using matplotlib's ax.plot\n",
    "    ax1.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, color=[0.72110727, 0.11649366, 0.2828143, 0.85])\n",
    "    ax1.fill_between(fpr, 0, tpr, alpha=0.2, color=[0.95686275, 0.42745098, 0.2627451, 0.85])  # auc shading\n",
    "    ax1.plot([0, 1], [0, 1], linestyle='--', color=[0.28742791, 0.41499423, 0.68512111, 0.85])  # random classifier\n",
    "    \n",
    "    # adjust ticks, labels, and title\n",
    "    ax1.tick_params(axis='both', labelsize=8)\n",
    "    ax1.set_xlabel('False Positive Rate', fontsize=9)\n",
    "    ax1.set_ylabel('True Positive Rate', fontsize=9)\n",
    "    ax1.set_title('ROC Curve, AUC = %0.2f' % roc_auc, fontsize=11)\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    \n",
    "    # plot the confusion matrix heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlBu_r', annot_kws={\"fontsize\":8}, ax=ax2)\n",
    "    cbar = ax2.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    ax2.tick_params(axis='both', labelsize=8)\n",
    "    ax2.set_xlabel('Predicted', fontsize=9)\n",
    "    ax2.set_ylabel('True', fontsize=9)\n",
    "    ax2.set_title('Confusion Matrix', fontsize=11)\n",
    "    plt.show()\n",
    "    # save the figure\n",
    "    #plt.savefig(f'plots/roc_auc_{method}_{seed}.png', bbox_inches='tight')\n",
    "    #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, method, seeds, balanced=blsmote, threshold=0.5):\n",
    "    np.random.seed(0)\n",
    "    r = []\n",
    "    models = []\n",
    "    test_pts = []\n",
    "\n",
    "    \n",
    "    for s in seeds:\n",
    "        print(f'* * * {method} for seed={s} * * * \\n')\n",
    "        X_train, X_test, y_train, y_test  = preprocess(data, s, preprocessing='mixed', log=False, ohe=True)\n",
    "        \n",
    "        print(f'Data pre-processed, fitting a {method} model...')       \n",
    "\n",
    "        clf = RunClf(X_train, y_train, method, balanced=balanced)\n",
    "\n",
    "        fitted, resampled_features, resampled_labels = clf.fit_tuned()\n",
    "        print(f'Best model: {fitted} \\n')\n",
    "        # predict labels:\n",
    "        probs_train, probs_test = fitted.predict_proba(np.array(resampled_features))[:,1], fitted.predict_proba(np.array(X_test))[:,1]\n",
    "        preds_train, preds_test = [int(i > threshold) for i in probs_train], [int(i > threshold) for i in probs_test]\n",
    "\n",
    "        print(f'Predicted test probabilities: {probs_test} \\n')\n",
    "        print(f'Predicted test labels: {preds_test} \\n')\n",
    "        \n",
    "        acc_train = accuracy_score(resampled_labels, preds_train)\n",
    "        prec_train = precision_score(resampled_labels, preds_train)\n",
    "        rec_train = recall_score(resampled_labels, preds_train)\n",
    "        f1_train = f1_score(resampled_labels, preds_train)\n",
    "        fpr, tpr, _ = roc_curve(np.array(resampled_labels), np.array(probs_train))\n",
    "        roc_auc_train = auc(fpr, tpr)\n",
    "        \n",
    "\n",
    "        acc_test = accuracy_score(y_test, preds_test)\n",
    "        prec_test = precision_score(y_test, preds_test)\n",
    "        rec_test = recall_score(y_test, preds_test)\n",
    "        f1_test = f1_score(y_test, preds_test)\n",
    "        fpr, tpr, _ = roc_curve(np.array(y_test), np.array(probs_test))\n",
    "        roc_auc_test = auc(fpr, tpr)\n",
    "        \n",
    "        print(f'Accuracy: {acc_test}, Precision: {prec_test}, Recall: {rec_test}, F1: {f1_test}, AUC: {roc_auc_test} \\n')\n",
    "        \n",
    "        cm_train, cm_test = confusion_matrix(resampled_labels, preds_train, labels=fitted.classes_), confusion_matrix(y_test, preds_test, labels=fitted.classes_)\n",
    "        # plot ROC curve and confusion matrix:\n",
    "        plot_roc(fpr, tpr, cm_test, method, s)\n",
    "        \n",
    "        r.append((acc_train, prec_train, rec_train, f1_train, roc_auc_train, cm_train, acc_test, prec_test, rec_test, f1_test, roc_auc_test, cm_test))\n",
    "        models.append(fitted)\n",
    "        test_pts.append([X_test, y_test])\n",
    " \n",
    "\n",
    " \n",
    "        \n",
    "    res = pd.DataFrame({'Accuracy (train)': [el[0] for el in r], \n",
    "                        'Precision (train)': [el[1] for el in r], \n",
    "                        'Recall (train)': [el[2] for el in r], \n",
    "                        'F1 (train)': [el[3] for el in r], \n",
    "                        'AUC (train)': [el[4] for el in r],\n",
    "                        'Accuracy (test)': [el[6] for el in r], \n",
    "                        'Precision (test)': [el[7] for el in r], \n",
    "                        'Recall (test)': [el[8] for el in r], \n",
    "                        'F1 (test)': [el[9] for el in r], \n",
    "                        'AUC (test)': [el[10] for el in r],\n",
    "                        'Method': method}, index=seeds)\n",
    "\n",
    "    return res, models, test_pts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the classifiers\n",
    "\n",
    "This will train for all 10 different data splits (as specified by the parameter `seeds`) and all classifiers (as specified in the `methods` list).\n",
    "\n",
    "Seeds used in the experiments:\n",
    "* **f-tve:** `[54321, 4321, 1234, 1, 123456, 98765, 56789, 5, 567890, 9876]` \n",
    "* **f-mth:** `[4321, 321, 123, 2, 12345, 9876, 5678, 6, 67890, 876]`\n",
    "* **bpu-lac:** `[321, 21, 12, 3, 1234, 987, 567, 7, 7890, 76]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-mth data is used for illustration\n",
    "methods = ['LogReg', 'SVC', 'RFC', 'GradBoostC']\n",
    "stats_mth = list(map(lambda m: evaluate_model(data_mth, m, seeds=[4321, 321, 123, 2, 12345, 9876, 5678, 6, 67890, 876]), methods))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mth = [el[0] for el in stats_mth] \n",
    "combined_df = pd.concat(metrics_mth)\n",
    "\n",
    "# 3. Optional: Reset the index, as all rows currently share the index '4321'\n",
    "metrics_mth_df = combined_df.reset_index(drop=True)\n",
    "metrics_mth_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve different elements of the estimated objects, one needs to use list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mth = [el[0] for el in stats_mth] # metrics\n",
    "clfs_mth = [el[1] for el in stats_mth] # classifiers - sklearn objects\n",
    "test_points_mth = [el[2] for el in stats_mth] # test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Bayesian Network and the retrieved Markov Blanket\n",
    "Example for the f-mth data and seed=6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndseed = 4321\n",
    "\n",
    "dmth = drop_dups(data_mth)\n",
    "dmth = set_coltypes(dmth)\n",
    "    \n",
    "# split the data into train and test, separate the target and the descriptors:\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(dmth.drop('Oxd', axis=1), dmth['Oxd'], test_size=0.2, random_state=rndseed)   \n",
    "#plot_label_dist(train_labels, rndseed)\n",
    "    \n",
    "    \n",
    "# drop cols with low variability in train, discretize the rest of the columns:\n",
    "train_data = drop_col(train_data)\n",
    "test_data = test_data[train_data.columns]\n",
    "train_data_ = train_data.copy()\n",
    "train_data_['Oxd'] = train_labels\n",
    "train_binned = bin_features_mdl(train_data_)\n",
    "# structure learning:\n",
    "\n",
    "hc = HillClimbSearch(train_binned)\n",
    "best_model = hc.estimate(scoring_method=BIC(train_binned), max_iter=200)\n",
    "    \n",
    "# instanciate and fit the Bayesian Network:\n",
    "model = DiscreteBayesianNetwork(best_model.edges())\n",
    "model.fit(train_binned, estimator=MaximumLikelihoodEstimator)\n",
    "        \n",
    "plot_bn_graph(model.edges(), rndseed, reduced=False, colormap=colormap)\n",
    "        \n",
    "# select relevant edges using the Markov blanket:\n",
    "relevant_edges = select_edges(model)\n",
    "plot_bn_graph(relevant_edges, rndseed, reduced=True, colormap=colormap)\n",
    "    \n",
    "edges = list(set([item for sublist in relevant_edges for item in sublist]))\n",
    "edges.remove('Oxd')\n",
    "train_data, test_data = train_data[edges], test_data[edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance (based on the RFC features) \n",
    "\n",
    "Access RFC feature importance scores.\n",
    "\n",
    "For accessing the test data, e.g. `test_points_mth[2][0][0]`, the 1st index stands for the method (2 - for `RFC` as indexed in the `methods` list, the 2nd - for the seed (0 - for `4321` as indexed in the `seeds` list), the very last 0 - for the design matrix (the labels are accessed as `test_points_mth[2][0][1]`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_idx = 4321\n",
    "feat = data_mth.copy()\n",
    "feat = feat.drop(\"Oxd\", axis=1)\n",
    "tgt = data_mth['Oxd']\n",
    "X_train, X_test, y_train, y_test = preprocess(data_mth, seed_idx, preprocessing='mixed', log=False, ohe=True)\n",
    "\n",
    "rfc_smote_ = stats_mth[2][1][0]\n",
    "rfc_smote = rfc_smote_.predict(X_train.to_numpy())\n",
    "\n",
    "# bar plot of the feature scores:\n",
    "plt.figure(figsize=(10, 10))\n",
    "feature_scores = pd.Series(rfc_smote_[4].feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "fscores = feature_scores.nlargest(n=len(feature_scores[feature_scores>0.00]), keep='first') # select all features with scores>0.01\n",
    "sns.barplot(x=fscores, y=fscores.index, hue=fscores.index, palette='RdYlBu', alpha=0.95, edgecolor='black', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Feature importance\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lacenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
